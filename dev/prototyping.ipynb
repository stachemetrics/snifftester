{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e239d6",
   "metadata": {},
   "source": [
    "# basic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec9cffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.2.1)\n",
      "Collecting google-genai\n",
      "  Downloading google_genai-1.57.0-py3-none-any.whl.metadata (53 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from google-genai) (4.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.46.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth[requests]<3.0.0,>=2.46.0->google-genai) (2.47.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /home/codespace/.local/lib/python3.12/site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-genai) (2.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home/codespace/.local/lib/python3.12/site-packages (from google-genai) (2.32.5)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from google-genai) (4.15.0)\n",
      "Collecting distro<2,>=1.7.0 (from google-genai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from google-genai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.46.0->google-auth[requests]<3.0.0,>=2.46.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.46.0->google-auth[requests]<3.0.0,>=2.46.0->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.46.0->google-auth[requests]<3.0.0,>=2.46.0->google-genai) (0.6.1)\n",
      "Downloading google_genai-1.57.0-py3-none-any.whl (713 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m713.3/713.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Installing collected packages: websockets, tenacity, distro, google-genai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [google-genai][0m [google-genai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 google-genai-1.57.0 tenacity-9.1.2 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b5b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "assert api_key is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09ef8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d527ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_TEXT = \"\"\"\n",
    "The impact of artificial intelligence on scientific research has been profound. According to a study \n",
    "published in Nature (Smith et al., 2023, \"AI-Driven Discovery in Materials Science\", \n",
    "DOI: 10.1038/s41586-023-06221-2), machine learning models have accelerated materials discovery by 50x.\n",
    "\n",
    "This trend is also reflected in social media discussions. A viral Twitter thread by @AIResearcher \n",
    "(https://twitter.com/AIResearcher/status/1234567890) garnered over 50,000 likes discussing how \n",
    "GPT-4 is being used in drug discovery pipelines.\n",
    "\n",
    "The New York Times reported on this phenomenon in their article \"The AI Revolution in Labs\" \n",
    "(https://www.nytimes.com/2023/08/15/science/ai-laboratory-research.html), noting that major \n",
    "pharmaceutical companies are investing billions.\n",
    "\n",
    "A Reddit discussion on r/MachineLearning (https://reddit.com/r/MachineLearning/comments/abc123) \n",
    "with 2,400 upvotes debated the reproducibility concerns raised in the original Nature paper.\n",
    "\n",
    "For a technical deep-dive, the arXiv preprint \"Transformer Architectures for Scientific Computing\" \n",
    "(arXiv:2401.12345) provides implementation details. The official documentation at \n",
    "https://docs.example-ai-tool.com/guide has step-by-step tutorials.\n",
    "\n",
    "Personal blog post by Dr. Jane Chen (https://janechenml.substack.com/p/ai-in-science-2024) \n",
    "offers a practitioner's perspective with 15,000 views.\n",
    "\n",
    "The CDC guidelines (https://www.cdc.gov/ai-health/guidelines.html) now include recommendations \n",
    "for AI-assisted diagnostics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb03c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTION_PROMPT = \"\"\"\n",
    "You are a reference extraction system. Analyze the following text and extract ALL references, citations, and sources mentioned.\n",
    "\n",
    "For each reference found, provide:\n",
    "1. raw_text: The exact text/citation as it appears\n",
    "2. type: One of: academic_journal, academic_preprint, news_media, government_official, social_media, personal_blog, documentation, unknown\n",
    "3. url: The URL if present (null if not)\n",
    "4. doi: The DOI if present (null if not)\n",
    "5. platform: The platform/source (e.g., \"Nature\", \"Twitter\", \"arXiv\", \"Reddit\", \"NYTimes\", etc.)\n",
    "6. engagement_signals: Any mentioned metrics like views, likes, upvotes (null if not mentioned)\n",
    "\n",
    "Return the results as a JSON array. Be thorough - extract every reference, even implicit ones.\n",
    "\n",
    "TEXT TO ANALYZE:\n",
    "---\n",
    "{text}\n",
    "---\n",
    "\n",
    "Return ONLY valid JSON, no markdown formatting or explanation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1d00c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_references(text: str) -> list[dict]:\n",
    "    \"\"\"Extract references from text using Gemini.\"\"\"\n",
    "    \n",
    "    prompt = EXTRACTION_PROMPT.format(text=text)\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    try:\n",
    "        response_text = response.text.strip()\n",
    "        # Clean up markdown code blocks if present\n",
    "        if response_text.startswith(\"```json\"):\n",
    "            response_text = response_text[7:]\n",
    "        if response_text.startswith(\"```\"):\n",
    "            response_text = response_text[3:]\n",
    "        if response_text.endswith(\"```\"):\n",
    "            response_text = response_text[:-3]\n",
    "        \n",
    "        return json.loads(response_text.strip())\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        print(f\"Raw response: {response.text}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5579bc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 references:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"raw_text\": \"Nature (Smith et al., 2023, \\\"AI-Driven Discovery in Materials Science\\\", DOI: 10.1038/s41586-023-06221-2)\",\n",
      "    \"type\": \"academic_journal\",\n",
      "    \"url\": null,\n",
      "    \"doi\": \"10.1038/s41586-023-06221-2\",\n",
      "    \"platform\": \"Nature\",\n",
      "    \"engagement_signals\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"@AIResearcher (https://twitter.com/AIResearcher/status/1234567890)\",\n",
      "    \"type\": \"social_media\",\n",
      "    \"url\": \"https://twitter.com/AIResearcher/status/1234567890\",\n",
      "    \"doi\": null,\n",
      "    \"platform\": \"Twitter\",\n",
      "    \"engagement_signals\": \"50,000 likes\"\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"The New York Times reported on this phenomenon in their article \\\"The AI Revolution in Labs\\\" (https://www.nytimes.com/2023/08/15/science/ai-laboratory-research.html)\",\n",
      "    \"type\": \"news_media\",\n",
      "    \"url\": \"https://www.nytimes.com/2023/08/15/science/ai-laboratory-research.html\",\n",
      "    \"doi\": null,\n",
      "    \"platform\": \"NYTimes\",\n",
      "    \"engagement_signals\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Reddit discussion on r/MachineLearning (https://reddit.com/r/MachineLearning/comments/abc123)\",\n",
      "    \"type\": \"social_media\",\n",
      "    \"url\": \"https://reddit.com/r/MachineLearning/comments/abc123\",\n",
      "    \"doi\": null,\n",
      "    \"platform\": \"Reddit\",\n",
      "    \"engagement_signals\": \"2,400 upvotes\"\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"arXiv preprint \\\"Transformer Architectures for Scientific Computing\\\" (arXiv:2401.12345)\",\n",
      "    \"type\": \"academic_preprint\",\n",
      "    \"url\": null,\n",
      "    \"doi\": null,\n",
      "    \"platform\": \"arXiv\",\n",
      "    \"engagement_signals\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"https://docs.example-ai-tool.com/guide\",\n",
      "    \"type\": \"documentation\",\n",
      "    \"url\": \"https://docs.example-ai-tool.com/guide\",\n",
      "    \"doi\": null,\n",
      "    \"platform\": \"docs.example-ai-tool.com\",\n",
      "    \"engagement_signals\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Personal blog post by Dr. Jane Chen (https://janechenml.substack.com/p/ai-in-science-2024)\",\n",
      "    \"type\": \"personal_blog\",\n",
      "    \"url\": \"https://janechenml.substack.com/p/ai-in-science-2024\",\n",
      "    \"doi\": null,\n",
      "    \"platform\": \"substack.com\",\n",
      "    \"engagement_signals\": \"15,000 views\"\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"The CDC guidelines (https://www.cdc.gov/ai-health/guidelines.html)\",\n",
      "    \"type\": \"government_official\",\n",
      "    \"url\": \"https://www.cdc.gov/ai-health/guidelines.html\",\n",
      "    \"doi\": null,\n",
      "    \"platform\": \"cdc.gov\",\n",
      "    \"engagement_signals\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "references = extract_references(SAMPLE_TEXT)\n",
    "print(f\"Found {len(references)} references:\\n\")\n",
    "print(json.dumps(references, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe875d",
   "metadata": {},
   "source": [
    "reflections:\n",
    "- data structure encourages hallucination - have not defined web search as a tool, so engagement_signals can be hallucinated.\n",
    "- may want to start with a digital heuristic - EEAT, experience expertise authorativeness trustworthiness\n",
    "- will want to log tokens in, tokens out, latency, to enable evaluation.\n",
    "- may want to start an examples folder with real outputs we've evaluated (to enable quality ratings) - or find another example elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7a82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e05f7ccf",
   "metadata": {},
   "source": [
    "# Iteration 2\n",
    "Get logging, improve prompt, provide outputs for UX elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6789f166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ generate_with_logging defined\n",
      "✅ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "@dataclass\n",
    "class LLMLog:\n",
    "    timestamp: str\n",
    "    model: str\n",
    "    prompt_tokens: int\n",
    "    completion_tokens: int\n",
    "    total_tokens: int\n",
    "    latency_ms: int\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "# Store logs for this session\n",
    "llm_logs: list[LLMLog] = []\n",
    "\n",
    "def generate_with_logging(prompt: str, model: str = \"gemini-2.0-flash-exp\") -> tuple[str, LLMLog]:\n",
    "    \"\"\"Generate content and log token usage + latency.\"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    latency_ms = int((time.time() - start_time) * 1000)\n",
    "    \n",
    "    usage = response.usage_metadata\n",
    "    log = LLMLog(\n",
    "        timestamp=datetime.now().isoformat(),\n",
    "        model=model,\n",
    "        prompt_tokens=usage.prompt_token_count,\n",
    "        completion_tokens=usage.candidates_token_count,\n",
    "        total_tokens=usage.total_token_count,\n",
    "        latency_ms=latency_ms\n",
    "    )\n",
    "    \n",
    "    llm_logs.append(log)\n",
    "    \n",
    "    return response.text, log\n",
    "\n",
    "print(\"✅ generate_with_logging defined\")\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51d5b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('example_question.txt',mode='r') as file:\n",
    "    EXAMPLE_QUESTION = file.read()\n",
    "\n",
    "with open('example_answer.txt',mode='r') as file:\n",
    "    EXAMPLE_ANSWER = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de49e09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1510c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data structures defined\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from enum import Enum\n",
    "\n",
    "class SourceType(str, Enum):\n",
    "    ACADEMIC_JOURNAL = \"academic_journal\"\n",
    "    ACADEMIC_PREPRINT = \"academic_preprint\"\n",
    "    NEWS_MEDIA = \"news_media\"\n",
    "    GOVERNMENT = \"government\"\n",
    "    SOCIAL_MEDIA = \"social_media\"\n",
    "    PERSONAL_BLOG = \"personal_blog\"\n",
    "    DOCUMENTATION = \"documentation\"\n",
    "    COMMERCIAL = \"commercial\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "@dataclass\n",
    "class ExtractedReference:\n",
    "    \"\"\"Stage 1 output - extracted from text only, no inference.\"\"\"\n",
    "    raw_text: str\n",
    "    url: Optional[str] = None\n",
    "    doi: Optional[str] = None\n",
    "    arxiv_id: Optional[str] = None\n",
    "    source_type: SourceType = SourceType.UNKNOWN\n",
    "    platform_name: Optional[str] = None\n",
    "    # Only what's explicitly in text\n",
    "    stated_author: Optional[str] = None\n",
    "    stated_date: Optional[str] = None\n",
    "    stated_metrics: Optional[str] = None  # e.g., \"2,400 upvotes\" as string\n",
    "\n",
    "@dataclass \n",
    "class CRAAPScore:\n",
    "    \"\"\"Stage 2 output - requires verification.\"\"\"\n",
    "    score: int  # 1-5\n",
    "    evidence: str  # Why this score\n",
    "    \n",
    "@dataclass\n",
    "class VerifiedReference:\n",
    "    \"\"\"Stage 2 output - after search/verification.\"\"\"\n",
    "    reference: ExtractedReference\n",
    "    url_accessible: Optional[bool] = None\n",
    "    currency: Optional[CRAAPScore] = None\n",
    "    relevance: Optional[CRAAPScore] = None\n",
    "    authority: Optional[CRAAPScore] = None\n",
    "    accuracy: Optional[CRAAPScore] = None\n",
    "    purpose: Optional[CRAAPScore] = None\n",
    "    overall_score: Optional[float] = None\n",
    "    verification_notes: str = \"\"\n",
    "\n",
    "@dataclass\n",
    "class AnalysisInput:\n",
    "    \"\"\"Full context for analysis.\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    context: dict = field(default_factory=dict)  # e.g., {\"user_location\": \"AU\", \"domain\": \"healthcare\"}\n",
    "\n",
    "print(\"✅ Data structures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29f5632e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ extract_references_v2 defined\n"
     ]
    }
   ],
   "source": [
    "EXTRACTION_PROMPT_V2 = \"\"\"\n",
    "You are a reference extraction system. Extract ALL references from an AI-generated answer.\n",
    "\n",
    "CONTEXT:\n",
    "- User's question: {question}\n",
    "- User's context: {context}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "Extract every reference, citation, URL, or source mentioned in the answer.\n",
    "Only extract information EXPLICITLY stated. Use null for anything not directly written.\n",
    "\n",
    "For each reference provide:\n",
    "- raw_text: Exact citation as written\n",
    "- url: URL if present, null otherwise\n",
    "- doi: DOI if present, null otherwise  \n",
    "- arxiv_id: arXiv ID if present, null otherwise\n",
    "- source_type: One of: academic_journal, academic_preprint, news_media, government, social_media, personal_blog, documentation, commercial, unknown\n",
    "- platform_name: Specific platform/publication name\n",
    "- stated_author: Author name if explicitly written, null otherwise\n",
    "- stated_date: Publication date/year if written, null otherwise\n",
    "- stated_metrics: Any engagement metrics as written (e.g., \"50k views\"), null otherwise\n",
    "\n",
    "ANSWER TO ANALYZE:\n",
    "---\n",
    "{answer}\n",
    "---\n",
    "\n",
    "Return ONLY a JSON array. Do not hallucinate - null for anything not explicit.\n",
    "\"\"\"\n",
    "\n",
    "def extract_references_v2(input_data: AnalysisInput) -> tuple[list[dict], LLMLog]:\n",
    "    \"\"\"Extract references with question context.\"\"\"\n",
    "    \n",
    "    prompt = EXTRACTION_PROMPT_V2.format(\n",
    "        question=input_data.question,\n",
    "        context=json.dumps(input_data.context),\n",
    "        answer=input_data.answer\n",
    "    )\n",
    "    \n",
    "    response_text, log = generate_with_logging(prompt)\n",
    "    \n",
    "    try:\n",
    "        clean_text = response_text.strip()\n",
    "        if clean_text.startswith(\"```json\"):\n",
    "            clean_text = clean_text[7:]\n",
    "        if clean_text.startswith(\"```\"):\n",
    "            clean_text = clean_text[3:]\n",
    "        if clean_text.endswith(\"```\"):\n",
    "            clean_text = clean_text[:-3]\n",
    "        \n",
    "        return json.loads(clean_text.strip()), log\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: {e}\\nRaw: {response_text}\")\n",
    "        return [], log\n",
    "\n",
    "print(\"✅ extract_references_v2 defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27a46e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ verify_reference_with_search defined\n"
     ]
    }
   ],
   "source": [
    "CRAAP_VERIFICATION_PROMPT = \"\"\"\n",
    "You are a source verification system evaluating references for a specific user question.\n",
    "\n",
    "USER QUESTION: {question}\n",
    "USER CONTEXT: {context}\n",
    "\n",
    "REFERENCE TO VERIFY:\n",
    "{reference_json}\n",
    "\n",
    "Using web search, evaluate this reference on the CRAAP framework. For each dimension, provide:\n",
    "- score: 1-5 (1=poor, 5=excellent)\n",
    "- evidence: Specific reasons for the score\n",
    "\n",
    "EVALUATION CRITERIA:\n",
    "\n",
    "**Currency (1-5):**\n",
    "- When was this published/updated?\n",
    "- Is the information current enough for the topic?\n",
    "- Are there more recent sources available?\n",
    "\n",
    "**Relevance (1-5):**\n",
    "- Does this source address the user's actual question?\n",
    "- Is it geographically relevant? (User is in {user_location})\n",
    "- Is it the right depth/audience level?\n",
    "\n",
    "**Authority (1-5):**\n",
    "- Who is the author? What are their credentials?\n",
    "- Is the publisher/platform reputable for this topic?\n",
    "- Is there institutional backing?\n",
    "\n",
    "**Accuracy (1-5):**\n",
    "- Can the claims be verified elsewhere?\n",
    "- Does the source cite its own references?\n",
    "- Is it peer-reviewed or edited?\n",
    "\n",
    "**Purpose (1-5):**\n",
    "- Why does this source exist? (inform/persuade/sell/entertain)\n",
    "- Is there obvious bias or conflict of interest?\n",
    "- Is it trying to sell something?\n",
    "\n",
    "Also check:\n",
    "- url_accessible: Can the URL be reached? (true/false/null if no URL)\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"url_accessible\": true/false/null,\n",
    "  \"currency\": {{\"score\": 1-5, \"evidence\": \"...\"}},\n",
    "  \"relevance\": {{\"score\": 1-5, \"evidence\": \"...\"}},\n",
    "  \"authority\": {{\"score\": 1-5, \"evidence\": \"...\"}},\n",
    "  \"accuracy\": {{\"score\": 1-5, \"evidence\": \"...\"}},\n",
    "  \"purpose\": {{\"score\": 1-5, \"evidence\": \"...\"}},\n",
    "  \"overall_score\": 1.0-5.0,\n",
    "  \"verification_notes\": \"Key findings from search\"\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "\"\"\"\n",
    "\n",
    "def verify_reference_with_search(\n",
    "    reference: dict, \n",
    "    question: str, \n",
    "    context: dict,\n",
    "    model: str = \"gemini-2.0-flash-exp\"\n",
    ") -> tuple[dict, LLMLog]:\n",
    "    \"\"\"Verify a single reference using Gemini with Google Search.\"\"\"\n",
    "    \n",
    "    prompt = CRAAP_VERIFICATION_PROMPT.format(\n",
    "        question=question,\n",
    "        context=json.dumps(context),\n",
    "        reference_json=json.dumps(reference, indent=2),\n",
    "        user_location=context.get(\"user_location\", \"unknown\")\n",
    "    )\n",
    "    \n",
    "    # Enable Google Search grounding\n",
    "    from google.genai import types\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=prompt,\n",
    "        config=types.GenerateContentConfig(\n",
    "            tools=[types.Tool(google_search=types.GoogleSearch())]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    latency_ms = int((time.time() - start_time) * 1000)\n",
    "    \n",
    "    usage = response.usage_metadata\n",
    "    log = LLMLog(\n",
    "        timestamp=datetime.now().isoformat(),\n",
    "        model=model,\n",
    "        prompt_tokens=usage.prompt_token_count,\n",
    "        completion_tokens=usage.candidates_token_count,\n",
    "        total_tokens=usage.total_token_count,\n",
    "        latency_ms=latency_ms\n",
    "    )\n",
    "    llm_logs.append(log)\n",
    "    \n",
    "    try:\n",
    "        clean_text = response.text.strip()\n",
    "        if clean_text.startswith(\"```json\"):\n",
    "            clean_text = clean_text[7:]\n",
    "        if clean_text.startswith(\"```\"):\n",
    "            clean_text = clean_text[3:]\n",
    "        if clean_text.endswith(\"```\"):\n",
    "            clean_text = clean_text[:-3]\n",
    "        \n",
    "        return json.loads(clean_text.strip()), log\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: {e}\\nRaw: {response.text}\")\n",
    "        return {}, log\n",
    "\n",
    "print(\"✅ verify_reference_with_search defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "981f59d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STAGE 1: EXTRACTION ===\n",
      "Tokens: 5678 | Latency: 10661ms\n",
      "Found 16 references\n",
      "[\n",
      "  {\n",
      "    \"raw_text\": \"iTnews\",\n",
      "    \"url\": \"https://www.itnews.com.au/feature/how-australian-businesses-can-overcome-the-struggle-to-move-ai-from-hype-to-reality-618510\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"news_media\",\n",
      "    \"platform_name\": \"iTnews\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Substack\",\n",
      "    \"url\": \"https://futureofprospecting.substack.com/p/the-ai-threat-that-could-break-salesforce\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"personal_blog\",\n",
      "    \"platform_name\": \"Substack\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"The Conversation\",\n",
      "    \"url\": \"https://theconversation.com/australian-businesses-have-actually-been-slow-to-adopt-ai-survey-finds-269812\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"news_media\",\n",
      "    \"platform_name\": \"The Conversation\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Windows Forum\",\n",
      "    \"url\": \"https://windowsforum.com/threads/australia-ai-adoption-from-copilot-wins-to-enterprise-scale-ai.389305/\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"unknown\",\n",
      "    \"platform_name\": \"Windows Forum\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Deloitte\",\n",
      "    \"url\": \"https://www.deloitte.com/au/en/services/consulting/analysis/state-generative-ai-enterprise.html\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"commercial\",\n",
      "    \"platform_name\": \"Deloitte\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"IT Brief Australia\",\n",
      "    \"url\": \"https://itbrief.com.au/story/australian-enterprises-lead-in-ai-adoption-but-face-data-hurdles\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"news_media\",\n",
      "    \"platform_name\": \"IT Brief Australia\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"PPC Land\",\n",
      "    \"url\": \"https://ppc.land/microsoft-ceo-admits-copilot-integrations-dont-really-work-as-adoption-falters/\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"news_media\",\n",
      "    \"platform_name\": \"PPC Land\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"The Missing Link\",\n",
      "    \"url\": \"https://www.themissinglink.com.au/news/navigating-copilot-adoption-challenges\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"news_media\",\n",
      "    \"platform_name\": \"The Missing Link\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Digital\",\n",
      "    \"url\": \"https://www.digital.gov.au/initiatives/copilot-trial/microsoft-365-copilot-evaluation-report-full/whole-government-adoption-generative-ai\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"government\",\n",
      "    \"platform_name\": \"Digital\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"CFO Dive\",\n",
      "    \"url\": \"https://www.cfodive.com/news/deloitte-ai-debacle-seen-wake-up-call-corporate-finance/802674/\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"news_media\",\n",
      "    \"platform_name\": \"CFO Dive\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Appinventiv\",\n",
      "    \"url\": \"https://appinventiv.com/blog/how-to-choose-right-ai-consulting-company-in-australia/\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"personal_blog\",\n",
      "    \"platform_name\": \"Appinventiv\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"PitchBook\",\n",
      "    \"url\": \"https://pitchbook.com/profiles/company/99585-55\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"commercial\",\n",
      "    \"platform_name\": \"PitchBook\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Mantel\",\n",
      "    \"url\": \"https://mantelgroup.com.au/\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"commercial\",\n",
      "    \"platform_name\": \"Mantel\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"BCG published \\\"AI Was Made for RevOps\\\" in September 2025\",\n",
      "    \"url\": null,\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"commercial\",\n",
      "    \"platform_name\": \"BCG\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": \"September 2025\",\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Nicola Lazzari\",\n",
      "    \"url\": \"https://nicolalazzari.ai/guides/ai-consultant-pricing-us\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"personal_blog\",\n",
      "    \"platform_name\": \"nicolalazzari.ai\",\n",
      "    \"stated_author\": \"Nicola Lazzari\",\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  },\n",
      "  {\n",
      "    \"raw_text\": \"Dasadvancedsystems\",\n",
      "    \"url\": \"https://dasadvancedsystems.com/blog/why-big-4-consulting-firms-are-failing-mid-size-companies-with-ai/\",\n",
      "    \"doi\": null,\n",
      "    \"arxiv_id\": null,\n",
      "    \"source_type\": \"personal_blog\",\n",
      "    \"platform_name\": \"Dasadvancedsystems.com\",\n",
      "    \"stated_author\": null,\n",
      "    \"stated_date\": null,\n",
      "    \"stated_metrics\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Replace with your actual example\n",
    "test_input = AnalysisInput(\n",
    "    question=EXAMPLE_QUESTION,\n",
    "    answer=EXAMPLE_ANSWER,\n",
    "    context={\n",
    "        \"user_location\": \"AU\",\n",
    "        \"domain\": \"AI consulting\",  # e.g., \"healthcare\", \"finance\", \"technology\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Stage 1: Extract\n",
    "print(\"=== STAGE 1: EXTRACTION ===\")\n",
    "refs, extract_log = extract_references_v2(test_input)\n",
    "print(f\"Tokens: {extract_log.total_tokens} | Latency: {extract_log.latency_ms}ms\")\n",
    "print(f\"Found {len(refs)} references\")\n",
    "print(json.dumps(refs, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17e1db55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STAGE 2: VERIFICATION ===\n",
      "\n",
      "Verifying 1/3: iTnews\n",
      "  Tokens: 1109 | Latency: 4178ms\n",
      "  Overall CRAAP Score: 3.6/5\n",
      "  Notes: The iTnews article seems generally relevant and authoritative, but the lack of a specific publicatio...\n",
      "\n",
      "Verifying 2/3: Substack\n",
      "  Tokens: 1124 | Latency: 4113ms\n",
      "  Overall CRAAP Score: 2.2/5\n",
      "  Notes: This Substack article discussing the AI threat to Salesforce is of limited value for researching the...\n",
      "\n",
      "Verifying 3/3: The Conversation\n",
      "  Tokens: 1018 | Latency: 3556ms\n",
      "  Overall CRAAP Score: 4.0/5\n",
      "  Notes: Key findings from search indicate that Australian businesses have been slow to adopt AI. This articl...\n",
      "\n",
      "=== FULL RESULTS ===\n",
      "[\n",
      "  {\n",
      "    \"reference\": {\n",
      "      \"raw_text\": \"iTnews\",\n",
      "      \"url\": \"https://www.itnews.com.au/feature/how-australian-businesses-can-overcome-the-struggle-to-move-ai-from-hype-to-reality-618510\",\n",
      "      \"doi\": null,\n",
      "      \"arxiv_id\": null,\n",
      "      \"source_type\": \"news_media\",\n",
      "      \"platform_name\": \"iTnews\",\n",
      "      \"stated_author\": null,\n",
      "      \"stated_date\": null,\n",
      "      \"stated_metrics\": null\n",
      "    },\n",
      "    \"verification\": {\n",
      "      \"url_accessible\": true,\n",
      "      \"currency\": {\n",
      "        \"score\": 3,\n",
      "        \"evidence\": \"The article doesn't have a clear publication date on the page itself, but the URL implies it was published in 2023 (618510). While this isn't extremely old, the AI field moves quickly, so more recent sources would be preferable. I will search for the publication date.\"\n",
      "      },\n",
      "      \"relevance\": {\n",
      "        \"score\": 4,\n",
      "        \"evidence\": \"The article discusses the challenges of implementing AI in Australian businesses, which is directly relevant to the user's context of AI consulting in Australia. It touches on the 'hype vs. reality' aspect, offering a potential angle for a unique selling proposition. The depth seems appropriate for a general business audience.\"\n",
      "      },\n",
      "      \"authority\": {\n",
      "        \"score\": 4,\n",
      "        \"evidence\": \"iTnews is a well-known Australian publication covering technology news. While the author isn't explicitly named in the provided information, iTnews generally has editorial oversight, suggesting a reasonable level of authority.\"\n",
      "      },\n",
      "      \"accuracy\": {\n",
      "        \"score\": 3,\n",
      "        \"evidence\": \"The article likely relies on reporting and industry insights rather than peer-reviewed research. It's difficult to verify the claims without more specific references or data within the article itself. Need to investigate if the article cites sources.\"\n",
      "      },\n",
      "      \"purpose\": {\n",
      "        \"score\": 4,\n",
      "        \"evidence\": \"The article appears to aim to inform readers about the challenges and opportunities of AI adoption in Australia. While iTnews might have a slight bias towards promoting technology adoption, there's no overt sales pitch or conflict of interest apparent from the title and context.\"\n",
      "      },\n",
      "      \"overall_score\": 3.6,\n",
      "      \"verification_notes\": \"The iTnews article seems generally relevant and authoritative, but the lack of a specific publication date and verifiable claims slightly weakens its overall score. It serves as a decent starting point for understanding the Australian AI market.\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"reference\": {\n",
      "      \"raw_text\": \"Substack\",\n",
      "      \"url\": \"https://futureofprospecting.substack.com/p/the-ai-threat-that-could-break-salesforce\",\n",
      "      \"doi\": null,\n",
      "      \"arxiv_id\": null,\n",
      "      \"source_type\": \"personal_blog\",\n",
      "      \"platform_name\": \"Substack\",\n",
      "      \"stated_author\": null,\n",
      "      \"stated_date\": null,\n",
      "      \"stated_metrics\": null\n",
      "    },\n",
      "    \"verification\": {\n",
      "      \"url_accessible\": true,\n",
      "      \"currency\": {\n",
      "        \"score\": 2,\n",
      "        \"evidence\": \"The stated date is null, making it impossible to determine how current the information is. Given the rapidly evolving nature of AI and its impact on sales and consulting, the lack of a date is a significant drawback. It's possible there are more recent and relevant sources available.\"\n",
      "      },\n",
      "      \"relevance\": {\n",
      "        \"score\": 2,\n",
      "        \"evidence\": \"While the article discusses AI and its impact on Salesforce, it doesn't directly address the Sydney data and operation consulting/product markets. It has some tangential relevance to the AI consulting domain but lacks geographical specificity (Australia) and doesn't provide insights into unique selling propositions for the Sydney market. The depth is more general than the user's specific needs.\"\n",
      "      },\n",
      "      \"authority\": {\n",
      "        \"score\": 2,\n",
      "        \"evidence\": \"The author is not stated, making it difficult to assess their credentials or expertise. Substack is a platform that hosts various personal blogs; therefore, the authority depends heavily on the author, which is unknown in this case. There is no institutional backing.\"\n",
      "      },\n",
      "      \"accuracy\": {\n",
      "        \"score\": 2,\n",
      "        \"evidence\": \"It is difficult to assess the accuracy of the claims without knowing the author or their sources. The source doesn't appear to cite its own references. Given that it's a personal blog on Substack, it is unlikely to be peer-reviewed or professionally edited.\"\n",
      "      },\n",
      "      \"purpose\": {\n",
      "        \"score\": 3,\n",
      "        \"evidence\": \"The purpose seems to be to inform or perhaps persuade readers about the potential impact of AI on Salesforce. Without knowing the author's background, it's difficult to determine if there are any biases or conflicts of interest. It's unclear if it is trying to sell something directly.\"\n",
      "      },\n",
      "      \"overall_score\": 2.2,\n",
      "      \"verification_notes\": \"This Substack article discussing the AI threat to Salesforce is of limited value for researching the Sydney data and operation consulting/product markets due to the lack of a publication date, unknown author, and general focus. It lacks geographical relevance and specific insights needed to develop a unique selling proposition.\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"reference\": {\n",
      "      \"raw_text\": \"The Conversation\",\n",
      "      \"url\": \"https://theconversation.com/australian-businesses-have-actually-been-slow-to-adopt-ai-survey-finds-269812\",\n",
      "      \"doi\": null,\n",
      "      \"arxiv_id\": null,\n",
      "      \"source_type\": \"news_media\",\n",
      "      \"platform_name\": \"The Conversation\",\n",
      "      \"stated_author\": null,\n",
      "      \"stated_date\": null,\n",
      "      \"stated_metrics\": null\n",
      "    },\n",
      "    \"verification\": {\n",
      "      \"url_accessible\": true,\n",
      "      \"currency\": {\n",
      "        \"score\": 3,\n",
      "        \"evidence\": \"The article was published in 2024. While not the most recent, it is recent enough to provide insights into AI adoption in Australia. More recent sources might offer updated statistics, but this provides a good overview.\"\n",
      "      },\n",
      "      \"relevance\": {\n",
      "        \"score\": 4,\n",
      "        \"evidence\": \"The article directly discusses AI adoption by Australian businesses, making it geographically relevant. It provides a high-level overview, which is useful for understanding the market context for AI consulting.\"\n",
      "      },\n",
      "      \"authority\": {\n",
      "        \"score\": 4,\n",
      "        \"evidence\": \"The Conversation is a reputable platform that publishes articles by academics and experts. While the stated author is not named in the provided reference, The Conversation generally provides author information on the article page. The platform is known for its expertise and balanced reporting.\"\n",
      "      },\n",
      "      \"accuracy\": {\n",
      "        \"score\": 4,\n",
      "        \"evidence\": \"The Conversation typically cites sources and presents information based on research or expert opinions. Claims are generally verifiable, and the platform adheres to editorial standards.\"\n",
      "      },\n",
      "      \"purpose\": {\n",
      "        \"score\": 5,\n",
      "        \"evidence\": \"The primary purpose of the article is to inform. The Conversation aims to provide accessible and factual information on various topics, including technology and business. There's no apparent bias or intention to sell a specific product or service.\"\n",
      "      },\n",
      "      \"overall_score\": 4.0,\n",
      "      \"verification_notes\": \"Key findings from search indicate that Australian businesses have been slow to adopt AI. This article from The Conversation provides an overview of AI adoption in Australia.\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STAGE 2: VERIFICATION ===\")\n",
    "\n",
    "verified_refs = []\n",
    "for i, ref in enumerate(refs[:3]):  # Limit to first 3 for testing\n",
    "    print(f\"\\nVerifying {i+1}/{min(3, len(refs))}: {ref.get('platform_name', 'unknown')}\")\n",
    "    \n",
    "    verification, verify_log = verify_reference_with_search(\n",
    "        ref, \n",
    "        test_input.question,\n",
    "        test_input.context\n",
    "    )\n",
    "    \n",
    "    print(f\"  Tokens: {verify_log.total_tokens} | Latency: {verify_log.latency_ms}ms\")\n",
    "    \n",
    "    if verification:\n",
    "        overall = verification.get('overall_score', 'N/A')\n",
    "        print(f\"  Overall CRAAP Score: {overall}/5\")\n",
    "        print(f\"  Notes: {verification.get('verification_notes', '')[:100]}...\")\n",
    "    \n",
    "    verified_refs.append({\n",
    "        \"reference\": ref,\n",
    "        \"verification\": verification\n",
    "    })\n",
    "\n",
    "print(\"\\n=== FULL RESULTS ===\")\n",
    "print(json.dumps(verified_refs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db6302b",
   "metadata": {},
   "source": [
    "quick check of logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba2ee6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.4.0 pandas-2.3.3 pytz-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b490a6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>latency_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-08T01:04:51.496310</td>\n",
       "      <td>gemini-2.0-flash-exp</td>\n",
       "      <td>3746</td>\n",
       "      <td>1932</td>\n",
       "      <td>5678</td>\n",
       "      <td>10661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-08T01:05:39.939271</td>\n",
       "      <td>gemini-2.0-flash-exp</td>\n",
       "      <td>651</td>\n",
       "      <td>458</td>\n",
       "      <td>1109</td>\n",
       "      <td>4178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-08T01:05:44.053101</td>\n",
       "      <td>gemini-2.0-flash-exp</td>\n",
       "      <td>627</td>\n",
       "      <td>497</td>\n",
       "      <td>1124</td>\n",
       "      <td>4113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-08T01:05:47.609839</td>\n",
       "      <td>gemini-2.0-flash-exp</td>\n",
       "      <td>636</td>\n",
       "      <td>382</td>\n",
       "      <td>1018</td>\n",
       "      <td>3556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp                 model  prompt_tokens  \\\n",
       "0  2026-01-08T01:04:51.496310  gemini-2.0-flash-exp           3746   \n",
       "1  2026-01-08T01:05:39.939271  gemini-2.0-flash-exp            651   \n",
       "2  2026-01-08T01:05:44.053101  gemini-2.0-flash-exp            627   \n",
       "3  2026-01-08T01:05:47.609839  gemini-2.0-flash-exp            636   \n",
       "\n",
       "   completion_tokens  total_tokens  latency_ms  \n",
       "0               1932          5678       10661  \n",
       "1                458          1109        4178  \n",
       "2                497          1124        4113  \n",
       "3                382          1018        3556  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_logs = pd.DataFrame([log.to_dict() for log in llm_logs])\n",
    "df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1a227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19ae04db",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
